{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorflow_version 1.x\n",
    "#For training we are taking meeting ES2015 - ES2015a,ES2015b,ES2015c,ES2015d\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "file_list = ['ES2015a', 'ES2015b', 'ES2015c', 'ES2015d']\n",
    "\n",
    "\n",
    "\n",
    "def extract_feature(file_name):\n",
    "    file = \"SPD/audio/\" + file_name + \".wav\"\n",
    "    frame_size = 2048\n",
    "    frame_shift = 512\n",
    "    y, sr = librosa.load(file)\n",
    "    print(\"Sampling Rate: \",sr)\n",
    "    #MFCC Extraction \n",
    "    mfccs = librosa.feature.mfcc(y, sr, n_mfcc=12, hop_length=frame_shift, n_fft=frame_size)\n",
    "    mfcc_delta = librosa.feature.delta(mfccs)\n",
    "    mfcc_delta2 = librosa.feature.delta(mfccs, order=2)\n",
    "\n",
    "    mfcc = mfccs[1:, ]\n",
    "    norm_mfcc = (mfcc - np.mean(mfcc, axis=1, keepdims=True)) / np.std(mfcc, axis=1, keepdims=True)\n",
    "    norm_mfcc_delta = (mfcc_delta - np.mean(mfcc_delta, axis=1, keepdims=True)) / np.std(mfcc_delta, axis=1, keepdims=True)\n",
    "    norm_mfcc_delta2= (mfcc_delta2 - np.mean(mfcc_delta2, axis=1, keepdims=True)) / np.std(mfcc_delta2, axis=1, keepdims=True)\n",
    "\n",
    "    ac_feature = np.vstack((norm_mfcc, norm_mfcc_delta, norm_mfcc_delta2))\n",
    "   \n",
    " #Loading Annotation File\n",
    "    ann = pd.read_csv('SPD/annotations_1.csv')\n",
    "    ann['End_point'] = ann['Duration'] + ann['Offset']\n",
    "\n",
    "    change_point = []\n",
    "    for i in range(len(ann['End_point'])):\n",
    "        dur_1 = int((ann['End_point'][i]-0.075)*sr)  # left 50ms\n",
    "        dur_2 = int((ann['End_point'][i]+0.075)*sr)  # right 50ms\n",
    "        change_point.append((dur_1, dur_2))\n",
    "   \n",
    "    sub_seq_len = int(3.2*sr/frame_shift)\n",
    "    sub_seq_step= int(0.8*sr/frame_shift)\n",
    "\n",
    "    feature_len = ac_feature.shape[1]\n",
    "\n",
    "    def is_change_point(n):\n",
    "        flag = False\n",
    "        for x in change_point:\n",
    "            if n > x[0] and n < x[1]:\n",
    "                flag = True\n",
    "                break\n",
    "\n",
    "            if n+frame_size-1 > x[0] and n+frame_size-1 < x[1]:\n",
    "                flag = True\n",
    "                break\n",
    "        return flag\n",
    "\n",
    "    sub_train_x = []\n",
    "    sub_train_y = []\n",
    "    for i in range(0, feature_len-sub_seq_len, sub_seq_step):\n",
    "        sub_seq_x = np.transpose(ac_feature[:, i: i+sub_seq_len])\n",
    "        sub_train_x.append(sub_seq_x[np.newaxis, :, :])\n",
    "        tmp = []\n",
    "        for index in range(i, i+sub_seq_len):\n",
    "            if is_change_point(index*frame_shift):\n",
    "                tmp.append(1)\n",
    "            else:\n",
    "                tmp.append(0)\n",
    "        lab_y = np.array(tmp)\n",
    "        lab_y = np.reshape(lab_y, (1, sub_seq_len))\n",
    "        sub_train_y.append(lab_y)\n",
    "    return sub_train_x, sub_train_y\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    for audio_file in file_list:\n",
    "        new_train_x, new_train_y = extract_feature(audio_file)\n",
    "        new_train_x = np.vstack(new_train_x)\n",
    "        new_train_y = np.vstack(new_train_y)\n",
    "        print(new_train_x.shape)\n",
    "        print(new_train_y.shape)\n",
    "\n",
    "        all_x.append(new_train_x)\n",
    "        all_y.append(new_train_y)\n",
    "    print(len(all_x))\n",
    "    print(len(all_y))\n",
    "\n",
    "    all_x_stack = np.vstack(all_x)\n",
    "    all_y_stack = np.vstack(all_y)\n",
    "    print(all_x_stack.shape, all_y_stack.shape)\n",
    "    print('over')\n",
    "    return all_x_stack, all_y_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, TimeDistributed, Dropout, LayerNormalization\n",
    "from keras.layers import LSTM\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Rate:  22050\n",
      "(1449, 137, 35)\n",
      "(1449, 137)\n",
      "Sampling Rate:  22050\n",
      "(2903, 137, 35)\n",
      "(2903, 137)\n",
      "Sampling Rate:  22050\n",
      "(2443, 137, 35)\n",
      "(2443, 137)\n",
      "Sampling Rate:  22050\n",
      "(2443, 137, 35)\n",
      "(2443, 137)\n",
      "4\n",
      "4\n",
      "(9238, 137, 35) (9238, 137)\n",
      "over\n",
      "(9238, 137) 1146113\n",
      "(9238, 137) 1146113\n"
     ]
    }
   ],
   "source": [
    "all_x, all_y = load_dataset()\n",
    "print(all_y.shape, np.sum(all_y))\n",
    "\n",
    "subsample_all_x = []\n",
    "subsample_all_y = []\n",
    "for index in range(all_y.shape[0]):\n",
    "  class_positive = sum(all_y[index])\n",
    "  if class_positive > 5:\n",
    "    subsample_all_x.append(all_x[index][np.newaxis, :, :])\n",
    "    subsample_all_y.append(all_y[index])\n",
    "\n",
    "all_x = np.vstack(subsample_all_x)\n",
    "all_y = np.vstack(subsample_all_y)\n",
    "print(all_y.shape, np.sum(all_y))\n",
    "\n",
    "all_y = all_y[:, :, np.newaxis]\n",
    "\n",
    "indices = np.random.permutation(all_x.shape[0])\n",
    "all_x_random = all_x[indices]\n",
    "all_y_random = all_y[indices]\n",
    "\n",
    "datasize = all_x_random.shape[0]\n",
    "train_size = int(datasize*0.97)\n",
    "train_x = all_x_random[0:train_size]\n",
    "valid_x = all_x_random[train_size:]\n",
    "\n",
    "train_y = all_y_random[0:train_size]\n",
    "valid_y = all_y_random[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, TimeDistributed, Dropout, LayerNormalization\n",
    "from keras.layers import LSTM\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137, 35)\n"
     ]
    }
   ],
   "source": [
    "input_shape = train_x.shape[1:]\n",
    "#input_shape = train_x.shape\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8960, 137, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to npy file\n",
    "save('SPD/train_x_15.npy', train_x)\n",
    "save('SPD/train_y_15.npy', train_y)\n",
    "save('SPD/valid_x_15.npy', valid_x)\n",
    "save('SPD/valid_y_15.npy', valid_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "041ad26dbb10a8661e7450419833b1f895b9404433ce6ce1546434e658537640"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
